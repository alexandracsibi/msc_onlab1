{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Load and combine datasets"
      ],
      "metadata": {
        "id": "I0UpjGP2h8v8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g_WnbBOGgXiK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_161 = pd.read_csv('/content/Colorectal_161_Summarized.csv', usecols=['summary', 'target_label'])\n",
        "df_201 = pd.read_csv('/content/Colorectal_201_Summarized.csv', usecols=['summary', 'target_label'])\n",
        "df_309 = pd.read_csv('/content/Colorectal_309_Summarized.csv', usecols=['summary', 'target_label'])\n",
        "df_213 = pd.read_csv('/content/Esophagael_213_Summarized.csv', usecols=['summary', 'target_label'])\n",
        "df_218 = pd.read_csv('/content/Lung_218_Summarized.csv', usecols=['summary', 'target_label'])\n",
        "df_261 = pd.read_csv('/content/Lung_261_Summarized.csv', usecols=['summary', 'target_label'])\n",
        "\n",
        "# Combine the dataframes into a single dataframe\n",
        "datasets = [df_161, df_201, df_309, df_213, df_218, df_261]\n",
        "#datasets = [df_161, df_201, df_309, df_213, df_261]\n",
        "combined_df = pd.concat(datasets).reset_index(drop=True)\n",
        "\n",
        "# Shuffle the combined dataframe to ensure data is mixed well\n",
        "combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "combined_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r1GARUOihM34",
        "outputId": "b5baa135-dda5-408e-efab-6a8b2d45e9ef"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   target_label                                            summary\n",
              "0             0  The patient is a female who underwent laparosc...\n",
              "1             0  The patient is a 62-year-old male of a race ca...\n",
              "2             0  The patient is a 57-year-old white male with a...\n",
              "3             0  The patient is a 62-year-old white female with...\n",
              "4             1  The patient is a female who underwent conventi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bc3b66a-c52c-448c-bd5d-16b0cb3ec286\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_label</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The patient is a female who underwent laparosc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>The patient is a 62-year-old male of a race ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The patient is a 57-year-old white male with a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>The patient is a 62-year-old white female with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>The patient is a female who underwent conventi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc3b66a-c52c-448c-bd5d-16b0cb3ec286')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bc3b66a-c52c-448c-bd5d-16b0cb3ec286 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bc3b66a-c52c-448c-bd5d-16b0cb3ec286');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b3fdda2-c76f-48d6-b125-c4e97af509fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b3fdda2-c76f-48d6-b125-c4e97af509fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b3fdda2-c76f-48d6-b125-c4e97af509fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 6002,\n  \"fields\": [\n    {\n      \"column\": \"target_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5904,\n        \"samples\": [\n          \"This patient is a 42-year-old white female with a BMI of 22.68. She is receiving treatment with FOLFOX + Cetuximab and has experienced a serious adverse effect. She has completed 2 cycles of chemotherapy. Her histology shows poorly differentiated cells. Despite experiencing symptoms, she is still able to be ambulatory. Her KRAS biomarker status is wild-type.\",\n          \"The patient is a male who underwent laparoscopic-assisted colectomy. He has abdominal wall adhesions and bowel adhesions, along with some complications post-surgery. He used narcotics for 3 days following the procedure. Despite experiencing symptoms, he is able to move around and be ambulatory. The pathology report indicates malignancy.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze and split the data"
      ],
      "metadata": {
        "id": "ctHQxQI_iS3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Count the occurrences of each class in the 'target_label' column\n",
        "class_counts = combined_df['target_label'].value_counts()\n",
        "print(class_counts)\n",
        "\n",
        "# Split data into train and validation/test\n",
        "train_df, temp_df = train_test_split(combined_df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the remaining data into validation and test sets\n",
        "validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(len(train_df), len(validation_df), len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjCWqscZh6UZ",
        "outputId": "c74925af-1bde-48f0-dc69-67a769d21c1d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target_label\n",
            "0    3725\n",
            "1    2277\n",
            "Name: count, dtype: int64\n",
            "4201 900 901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clinical BERT model define"
      ],
      "metadata": {
        "id": "XwTwWZGVidyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "class ClinicalBERTClassifier(nn.Module):\n",
        "    def __init__(self, bert_model='emilyalsentzer/Bio_ClinicalBERT', num_labels=2, device='cuda'):\n",
        "        super(ClinicalBERTClassifier, self).__init__()\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "        self.bert = AutoModel.from_pretrained(bert_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)  # Classifier layer\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get the output from BERT\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)  # Apply dropout\n",
        "        logits = self.classifier(pooled_output)  # Pass through the classifier\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "Mgpe-JzbiiM1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data tokenization"
      ],
      "metadata": {
        "id": "hyDN2HI2ivJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
        "\n",
        "def tokenize_data(df):\n",
        "    # Tokenize text to convert to BERT's input format\n",
        "    # max_lenght 200 instead of default 512\n",
        "    return tokenizer(df['summary'].tolist(), padding='max_length', truncation=True, max_length=150, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRcJ2RSzizoy",
        "outputId": "64902e03-06dc-41d5-fe56-9e813e699b81"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the right max_length"
      ],
      "metadata": {
        "id": "xvTjfBnGi5-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize without truncation and find the maximum length\n",
        "token_lens = []\n",
        "for txt in combined_df['summary']:\n",
        "    tokens = tokenizer.encode(txt, add_special_tokens=True)\n",
        "    token_lens.append(len(tokens))\n",
        "\n",
        "print('Max length: ', max(token_lens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7h-0hn3jDEl",
        "outputId": "34693b8f-b851-4348-ac0f-db85759c5798"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoaders"
      ],
      "metadata": {
        "id": "vNj7dqBOjJRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def create_data_loader(df, tokenizer, batch_size=64):\n",
        "    # Tokenize the text data\n",
        "    encodings = tokenize_data(df)\n",
        "    labels = torch.tensor(df['target_label'].values)\n",
        "\n",
        "    # Create a dataset from the encodings and labels\n",
        "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
        "    # Create a DataLoader\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Assuming train_df, validation_df, and test_df are already defined\n",
        "train_loader = create_data_loader(train_df, tokenizer)\n",
        "validation_loader = create_data_loader(validation_df, tokenizer)\n",
        "test_loader = create_data_loader(test_df, tokenizer)\n"
      ],
      "metadata": {
        "id": "Hb-cj1OtjI5m"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "G2_ZjDNqkZWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def calculate_metrics(preds, labels):\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average='binary')\n",
        "    recall = recall_score(labels, preds, average='binary')\n",
        "    f1 = f1_score(labels, preds, average='binary')\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "DmMCRuEjkbwV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Evaluate"
      ],
      "metadata": {
        "id": "zsqGmb_hjj_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        input_ids, attention_mask, label = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs, label)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # if i % 30 == 0:\n",
        "        #   print(f\"Batch {i}, Current Train Loss: {loss.item()}\")\n",
        "    return total_loss / len(data_loader)  # Return the average loss\n",
        "\n",
        "def evaluate(model, data_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions, actual_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            input_ids, attention_mask, labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)  # predicted classes\n",
        "            predictions.append(preds)\n",
        "            actual_labels.append(labels)\n",
        "\n",
        "    predictions = torch.cat(predictions).cpu().numpy()\n",
        "    actual_labels = torch.cat(actual_labels).cpu().numpy()\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(predictions, actual_labels)  # additional metrics\n",
        "    return average_loss, accuracy, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "AAmyjPwzjjxQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization + Training + Validating the model"
      ],
      "metadata": {
        "id": "gJlckLF_jpi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = ClinicalBERTClassifier()"
      ],
      "metadata": {
        "id": "S9-b7IxCuNeM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.optim as optim\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "\n",
        "num_epochs = 7\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 3e-4\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(combined_df['target_label']), y=combined_df['target_label'].values)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(model.device)\n",
        "\n",
        "# Use these weights in your loss function\n",
        "#loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Use a scheduler to reduce learning rate when a metric has stopped improving\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# Early stopping criteria\n",
        "best_val_loss = float('inf')\n",
        "patience = 2\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn, model.device)\n",
        "    val_loss, val_acc, val_prec, val_recall, val_f1 = evaluate(model, validation_loader, loss_fn, model.device)\n",
        "    scheduler.step()\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}:\")\n",
        "    print(f\"  Train Loss: {train_loss}\")\n",
        "    print(f\"  Validation Loss: {val_loss}\")\n",
        "    print(f\"  Validation Accuracy: {val_acc}\")\n",
        "    print(f\"  Validation Precision: {val_prec}\")\n",
        "    print(f\"  Validation Recall: {val_recall}\")\n",
        "    print(f\"  Validation F1: {val_f1}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiUpO6eUtpxY",
        "outputId": "7a4b7c44-58f3-497f-d868-39bf4e7b40cb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "  Train Loss: 0.44519587990009424\n",
            "  Validation Loss: 0.5031834701697032\n",
            "  Validation Accuracy: 0.7944444444444444\n",
            "  Validation Precision: 0.7865168539325843\n",
            "  Validation Recall: 0.621301775147929\n",
            "  Validation F1: 0.6942148760330578\n",
            "\n",
            "Epoch 2:\n",
            "  Train Loss: 0.43670621378855273\n",
            "  Validation Loss: 0.4607324242591858\n",
            "  Validation Accuracy: 0.7988888888888889\n",
            "  Validation Precision: 0.7223796033994334\n",
            "  Validation Recall: 0.7544378698224852\n",
            "  Validation F1: 0.7380607814761215\n",
            "\n",
            "Epoch 3:\n",
            "  Train Loss: 0.42551373171083856\n",
            "  Validation Loss: 0.4441918889681498\n",
            "  Validation Accuracy: 0.7788888888888889\n",
            "  Validation Precision: 0.7907949790794979\n",
            "  Validation Recall: 0.5591715976331361\n",
            "  Validation F1: 0.6551126516464472\n",
            "\n",
            "Epoch 4:\n",
            "  Train Loss: 0.41105386208404193\n",
            "  Validation Loss: 0.4449521799882253\n",
            "  Validation Accuracy: 0.8044444444444444\n",
            "  Validation Precision: 0.7425149700598802\n",
            "  Validation Recall: 0.7337278106508875\n",
            "  Validation F1: 0.7380952380952381\n",
            "\n",
            "Early stopping at epoch 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and load the model"
      ],
      "metadata": {
        "id": "MmdJJE1klaYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/clinical_bert_classifier2.pth'\n",
        "\n",
        "# Save the model state\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "RlePx7qcoqrl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRVuyazQpA-g",
        "outputId": "a3a48357-96ba-4305-caa1-b3a3230a7f38"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the model state into a model's instance:\n",
        "model = ClinicalBERTClassifier()  # Initialize the model again\n",
        "model.load_state_dict(torch.load('clinical_bert_classifier.pth'))\n",
        "model = model.to(model.device)  # Move model to appropriate device"
      ],
      "metadata": {
        "id": "eOiQreGKpjCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the model"
      ],
      "metadata": {
        "id": "1erYyijXl_F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader, loss_fn, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    predictions, labels = [], []\n",
        "\n",
        "    with torch.no_grad():  # No gradient needed for evaluation\n",
        "        for batch in data_loader:\n",
        "            input_ids, attention_mask, label = [b.to(device) for b in batch]\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = loss_fn(outputs, label)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            labels.extend(label.cpu().numpy())\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(predictions, labels)\n",
        "    return average_loss, accuracy, precision, recall, f1\n",
        "\n",
        "# Assuming you have a DataLoader for your test data\n",
        "test_loss, test_acc, test_prec, test_recall, test_f1 = test(model, test_loader, loss_fn, model.device)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "print(f\"Test Precision: {test_prec}\")\n",
        "print(f\"Test Recall: {test_recall}\")\n",
        "print(f\"Test F1: {test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m7v2bI2mA_N",
        "outputId": "bb0d5da7-0659-4b64-ed3c-2465fb583466"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.47705430785814923\n",
            "Test Accuracy: 0.781354051054384\n",
            "Test Precision: 0.6916666666666667\n",
            "Test Recall: 0.7432835820895523\n",
            "Test F1: 0.7165467625899281\n"
          ]
        }
      ]
    }
  ]
}